# Content Safety Rules

This document outlines the content moderation and safety rules for the horror TikTok video generation pipeline.

## Overview

All generated content must comply with content safety guidelines to ensure:
- User safety and well-being
- Platform compliance (TikTok community guidelines)
- Legal compliance
- Ethical content creation

## Prohibited Content Categories

### 1. Self-Harm and Suicide

**Strictly Prohibited:**
- Any depiction or mention of self-harm
- Suicide ideation or methods
- Content that could encourage self-destructive behavior
- Instructions or guidance on self-harm

**Why:** This content can be triggering and harmful to vulnerable audiences.

### 2. Extreme Violence and Gore

**Prohibited:**
- Graphic descriptions of extreme violence
- Detailed gore or mutilation
- Realistic depictions of serious injury or death
- Violence against identifiable individuals

**Allowed:**
- Implied horror and suspense
- Non-graphic supernatural horror
- Psychological thriller elements
- Tension and fear without explicit violence

**Why:** While horror content is the goal, extreme violence crosses ethical boundaries and violates platform guidelines.

### 3. Content Involving Minors

**Strictly Prohibited:**
- Any horror content featuring children
- Content that could endanger or frighten children
- Stories targeting children as victims
- Child endangerment themes

**Why:** Content involving minors in horror scenarios is unethical and violates platform policies.

### 4. Sexual Content

**Prohibited:**
- Sexual or suggestive content
- Nudity or sexual situations
- Sexual violence or assault themes
- Adult content of any kind

**Why:** This is a horror content generator, not adult content. Sexual content violates TikTok guidelines.

### 5. Hate Speech and Discrimination

**Prohibited:**
- Content promoting hate based on race, religion, ethnicity, etc.
- Discriminatory stereotypes
- Content that dehumanizes groups of people
- Extremist ideologies

**Why:** Hate speech is harmful and violates basic ethical standards.

### 6. Dangerous Acts and Challenges

**Prohibited:**
- Content encouraging dangerous activities
- "Challenges" that could cause harm
- Instructions for illegal activities
- Promotion of dangerous substances

**Why:** User safety is paramount.

### 7. Misinformation

**Prohibited:**
- False information about real people or events
- Conspiracy theories
- Medical misinformation
- Deliberate deception

**Why:** Even in fiction, we should not spread harmful misinformation.

## Allowed Horror Content

### Acceptable Themes

✅ **Supernatural Horror**
- Ghosts, spirits, hauntings
- Paranormal phenomena
- Mysterious occurrences
- Cursed objects or locations

✅ **Psychological Horror**
- Suspense and tension
- Mysterious situations
- Mind games and mysteries
- Atmospheric fear

✅ **Urban Legends and Folklore**
- Traditional horror stories
- Cultural ghost stories
- Mystery and suspense narratives
- Campfire-style horror

✅ **Monster Stories**
- Fictional creatures
- Non-graphic monster encounters
- Mystery creatures
- Mythological beings

### Content Guidelines

**Story Construction:**
- Focus on suspense and atmosphere over explicit content
- Use implied horror rather than graphic descriptions
- Build tension through mystery and unknown elements
- Create fear through suggestion, not explicit violence

**Language:**
- Avoid graphic or excessive profanity
- Use suspenseful and atmospheric descriptions
- Keep language appropriate for mature teen/adult audiences
- No slurs or offensive language

**Pacing:**
- Build suspense gradually
- Create atmosphere and mood
- Use cliffhangers and mysteries
- Keep content engaging without shock value

## Content Moderation Process

### 1. Pre-Generation Check
- Validate input prompts for prohibited themes
- Check against keyword blacklist
- Review for potential policy violations

### 2. Story Generation Review
- Analyze generated story for prohibited content
- Check each scene for safety compliance
- Validate narrative doesn't cross ethical lines
- Ensure content fits allowed themes

### 3. Visual Content Check
- Review image generation prompts
- Ensure prompts won't generate prohibited visuals
- Validate image descriptions are appropriate

### 4. Final Review
- Complete story safety check
- Verify no prohibited elements slipped through
- Confirm content meets quality standards
- Approve for rendering

### 5. Human Review (Future)
- Flagged content reviewed by human moderators
- Edge cases escalated for decision
- Continuous improvement of filters

## Moderation Thresholds

### Automated Filtering

**Reject Immediately:**
- Exact matches to prohibited keywords
- Clear policy violations
- Extreme content indicators

**Flag for Review:**
- Borderline content
- Ambiguous themes
- Context-dependent scenarios

**Allow:**
- Clear compliance with guidelines
- Acceptable horror themes
- Content within boundaries

## Keyword Blacklists

### Hard Blocks (Auto-reject)
- Self-harm terms
- Suicide-related terms
- Child endangerment terms
- Extreme violence descriptors
- Hate speech terms
- Sexual content terms

### Soft Blocks (Flag for review)
- Violence-adjacent terms
- Potentially sensitive topics
- Context-dependent terms

## Appeals and Overrides

**Future Implementation:**
- Manual review process for rejected content
- Appeal mechanism for false positives
- Admin override for edge cases
- Logging of all moderation decisions

## Regional Compliance

Content must comply with regulations in:
- United States (COPPA, FTC guidelines)
- European Union (GDPR, DSA)
- United Kingdom (Online Safety Bill)
- Other major markets

## Continuous Improvement

### Monitoring
- Track moderation decisions
- Analyze false positives/negatives
- Monitor user feedback
- Review edge cases

### Updates
- Regular review of policies
- Update based on platform changes
- Incorporate new safety research
- Community feedback integration

## Reporting

### Internal Logging
- All content moderation decisions logged
- Timestamp and reason recorded
- Reviewer (human/AI) identified
- Decision can be audited

### Transparency
- Users informed when content rejected
- Reason provided (general category)
- Guidance on acceptable alternatives
- Clear policy communication

## Emergency Procedures

**If Harmful Content Released:**
1. Immediately suspend system
2. Remove problematic content
3. Investigate root cause
4. Update filters
5. Test thoroughly
6. Document incident
7. Implement preventive measures

## Ethical Considerations

Beyond legal compliance, we commit to:
- Prioritizing user safety
- Avoiding exploitation of fears
- Respecting cultural sensitivities
- Creating entertaining, not harmful, content
- Being transparent about AI generation
- Maintaining ethical standards

## Review Schedule

This policy will be reviewed:
- Monthly for first 6 months
- Quarterly after stabilization
- After any significant incident
- When platform policies change
- Based on legal/regulatory updates
